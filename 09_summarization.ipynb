{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization with Hugging Face üìÑ\n",
    "\n",
    "Text summarization creates concise versions of longer documents while preserving the most important information. From news articles to research papers, summarization helps us quickly understand the essence of lengthy content.\n",
    "\n",
    "## What is Text Summarization?\n",
    "\n",
    "**Text Summarization** condenses text while maintaining key meaning:\n",
    "- **Input**: Long document or article\n",
    "- **Output**: Shorter text containing main points\n",
    "- **Types**: Extractive (select sentences) vs Abstractive (generate new text)\n",
    "- **Examples**: News summaries, research abstracts, meeting notes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll know how to:\n",
    "1. Use pre-trained summarization models effectively\n",
    "2. Control summary length and style parameters\n",
    "3. Compare different summarization approaches\n",
    "4. Handle various document types and domains\n",
    "5. Evaluate and improve summary quality\n",
    "6. Build production-ready summarization systems\n",
    "\n",
    "Let's start condensing information efficiently! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rouge_score import rouge_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text Summarization\n",
    "\n",
    "Let's start with pre-trained summarization models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text summarization with pre-trained models\n",
    "print(\"üìÑ Basic Text Summarization\")\n",
    "print(\"=\" * 29)\n",
    "\n",
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Sample news articles\n",
    "sample_articles = [\n",
    "    {\n",
    "        \"title\": \"AI Technology Breakthrough\",\n",
    "        \"text\": \"\"\"\n",
    "        Artificial intelligence researchers at Stanford University have announced a significant breakthrough \n",
    "        in natural language processing that could revolutionize how computers understand human communication. \n",
    "        The new model, called GPT-Advanced, demonstrates unprecedented accuracy in language translation, \n",
    "        text summarization, and question answering tasks. According to the research team, led by Dr. Sarah \n",
    "        Johnson, the model achieved a 95% accuracy rate on standard benchmarks, surpassing previous \n",
    "        state-of-the-art models by 15%. The breakthrough comes from a novel training approach that \n",
    "        combines supervised learning with reinforcement learning techniques. The researchers trained \n",
    "        the model on a diverse dataset containing over 100 billion parameters, making it one of the \n",
    "        largest language models ever created. Industry experts believe this advancement could have \n",
    "        far-reaching implications for various applications, including virtual assistants, automated \n",
    "        customer service, and educational tools. The research paper has been submitted to the \n",
    "        International Conference on Machine Learning and is expected to be published next month.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Climate Change Report\",\n",
    "        \"text\": \"\"\"\n",
    "        The latest report from the Intergovernmental Panel on Climate Change (IPCC) presents alarming \n",
    "        findings about the current state of global warming and its projected impacts on human civilization. \n",
    "        The comprehensive study, involving over 200 scientists from 50 countries, indicates that global \n",
    "        temperatures have risen by 1.2 degrees Celsius since pre-industrial times, with the last decade \n",
    "        being the warmest on record. The report highlights several critical tipping points that could \n",
    "        trigger irreversible changes in Earth's climate system, including the collapse of major ice \n",
    "        sheets in Antarctica and Greenland, the shutdown of ocean circulation patterns, and the \n",
    "        widespread loss of tropical forests. Scientists warn that without immediate and drastic \n",
    "        reductions in greenhouse gas emissions, these tipping points could be reached within the \n",
    "        next two decades. The economic implications are staggering, with potential damages estimated \n",
    "        at over $20 trillion globally by 2050. The report calls for unprecedented international \n",
    "        cooperation to transition to renewable energy sources and implement carbon capture technologies.\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, article in enumerate(sample_articles, 1):\n",
    "    print(f\"\\nüì∞ Article {i}: {article['title']}\")\n",
    "    print(f\"Original length: {len(article['text'].split())} words\")\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarizer(article['text'], max_length=100, min_length=30, do_sample=False)\n",
    "    summary_text = summary[0]['summary_text']\n",
    "    \n",
    "    print(f\"Summary length: {len(summary_text.split())} words\")\n",
    "    print(f\"Compression ratio: {len(summary_text.split()) / len(article['text'].split()):.2f}\")\n",
    "    print(f\"\\nüìù Summary: {summary_text}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Controlling Summary Parameters\n",
    "\n",
    "Learn how to fine-tune summary length, style, and quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced summarization with parameter control\n",
    "print(\"‚öôÔ∏è Controlling Summary Parameters\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "# Sample long text for testing different parameters\n",
    "long_text = \"\"\"\n",
    "Machine learning has transformed numerous industries over the past decade, from healthcare and \n",
    "finance to transportation and entertainment. In healthcare, ML algorithms are being used to \n",
    "analyze medical images, predict patient outcomes, and discover new drugs. For example, \n",
    "Google's DeepMind developed an AI system that can detect over 50 eye diseases with \n",
    "unprecedented accuracy. In finance, algorithmic trading systems process millions of \n",
    "transactions per second, while fraud detection systems protect consumers from unauthorized \n",
    "activities. The transportation industry has seen remarkable advances with autonomous vehicles, \n",
    "where companies like Tesla and Waymo are leading the development of self-driving cars. \n",
    "Entertainment platforms like Netflix and Spotify use recommendation algorithms to personalize \n",
    "content for billions of users worldwide. However, the rapid adoption of ML also raises \n",
    "important ethical considerations, including privacy concerns, algorithmic bias, and job \n",
    "displacement. Researchers and policymakers are working together to develop guidelines and \n",
    "regulations that ensure AI systems are fair, transparent, and beneficial to society. The \n",
    "future of machine learning looks promising, with emerging technologies like quantum computing \n",
    "and neuromorphic chips potentially unlocking even more powerful AI capabilities.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Original text: {len(long_text.split())} words\\n\")\n",
    "\n",
    "# Test different summary lengths\n",
    "summary_configs = [\n",
    "    {\"name\": \"Short Summary\", \"max_length\": 50, \"min_length\": 20},\n",
    "    {\"name\": \"Medium Summary\", \"max_length\": 100, \"min_length\": 40},\n",
    "    {\"name\": \"Long Summary\", \"max_length\": 150, \"min_length\": 80}\n",
    "]\n",
    "\n",
    "for config in summary_configs:\n",
    "    print(f\"üîß {config['name']} ({config['min_length']}-{config['max_length']} words):\")\n",
    "    \n",
    "    summary = summarizer(\n",
    "        long_text, \n",
    "        max_length=config['max_length'], \n",
    "        min_length=config['min_length'], \n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    summary_text = summary[0]['summary_text']\n",
    "    actual_length = len(summary_text.split())\n",
    "    compression = actual_length / len(long_text.split())\n",
    "    \n",
    "    print(f\"   Actual length: {actual_length} words\")\n",
    "    print(f\"   Compression: {compression:.2f} ({compression*100:.1f}% of original)\")\n",
    "    print(f\"   Text: {summary_text}\")\n",
    "    print()\n",
    "\n",
    "# Test different sampling strategies\n",
    "print(\"üé≤ Different Sampling Strategies:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "sampling_configs = [\n",
    "    {\"name\": \"Deterministic\", \"do_sample\": False, \"temperature\": None},\n",
    "    {\"name\": \"Creative (High Temp)\", \"do_sample\": True, \"temperature\": 1.2},\n",
    "    {\"name\": \"Conservative (Low Temp)\", \"do_sample\": True, \"temperature\": 0.3}\n",
    "]\n",
    "\n",
    "for config in sampling_configs:\n",
    "    print(f\"\\nüîÑ {config['name']}:\")\n",
    "    \n",
    "    if config['temperature']:\n",
    "        summary = summarizer(\n",
    "            long_text, \n",
    "            max_length=80, \n",
    "            min_length=40,\n",
    "            do_sample=config['do_sample'],\n",
    "            temperature=config['temperature']\n",
    "        )\n",
    "    else:\n",
    "        summary = summarizer(\n",
    "            long_text, \n",
    "            max_length=80, \n",
    "            min_length=40,\n",
    "            do_sample=config['do_sample']\n",
    "        )\n",
    "    \n",
    "    print(f\"   {summary[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Document Summarization\n",
    "\n",
    "Summarize multiple related documents into a cohesive summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-document summarization\n",
    "print(\"üìö Multi-Document Summarization\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Related articles about a common topic\n",
    "related_articles = [\n",
    "    {\n",
    "        \"source\": \"Tech News Daily\",\n",
    "        \"content\": \"\"\"\n",
    "        Apple announced its latest iPhone 15 series featuring significant improvements in camera \n",
    "        technology and battery life. The new devices include advanced computational photography \n",
    "        capabilities powered by the A17 Pro chip. Industry analysts expect strong sales during \n",
    "        the holiday season, with pre-orders already exceeding initial supply. The company also \n",
    "        introduced new sustainability features, including recycled materials and carbon-neutral \n",
    "        packaging.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"Business Weekly\",\n",
    "        \"content\": \"\"\"\n",
    "        Apple's stock price surged 5% following the iPhone 15 announcement, with investors \n",
    "        showing confidence in the company's continued innovation. Market research firms predict \n",
    "        the new iPhone will capture significant market share from Android competitors. The \n",
    "        improved camera features and longer battery life address key consumer demands. Apple's \n",
    "        services revenue is also expected to benefit from increased hardware sales.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"Consumer Reports\",\n",
    "        \"content\": \"\"\"\n",
    "        Early reviews of the iPhone 15 highlight exceptional photo quality and impressive \n",
    "        all-day battery performance. The new titanium design feels premium while being \n",
    "        lighter than previous models. However, the higher price point may limit adoption \n",
    "        among budget-conscious consumers. The improved durability and water resistance \n",
    "        features received positive feedback from reviewers.\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class MultiDocumentSummarizer:\n",
    "    def __init__(self):\n",
    "        self.summarizer = pipeline(\"summarization\")\n",
    "    \n",
    "    def summarize_collection(self, documents, strategy=\"concatenate\"):\n",
    "        \"\"\"Summarize multiple documents using different strategies\"\"\"\n",
    "        \n",
    "        if strategy == \"concatenate\":\n",
    "            # Combine all documents and summarize together\n",
    "            combined_text = \" \".join([doc[\"content\"] for doc in documents])\n",
    "            summary = self.summarizer(combined_text, max_length=120, min_length=50, do_sample=False)\n",
    "            return summary[0]['summary_text']\n",
    "        \n",
    "        elif strategy == \"individual_then_combine\":\n",
    "            # Summarize each document individually, then combine summaries\n",
    "            individual_summaries = []\n",
    "            \n",
    "            for doc in documents:\n",
    "                summary = self.summarizer(doc[\"content\"], max_length=50, min_length=20, do_sample=False)\n",
    "                individual_summaries.append(summary[0]['summary_text'])\n",
    "            \n",
    "            # Combine individual summaries\n",
    "            combined_summaries = \" \".join(individual_summaries)\n",
    "            final_summary = self.summarizer(combined_summaries, max_length=100, min_length=40, do_sample=False)\n",
    "            return final_summary[0]['summary_text']\n",
    "        \n",
    "        elif strategy == \"extractive\":\n",
    "            # Extract key sentences from each document\n",
    "            key_sentences = []\n",
    "            for doc in documents:\n",
    "                sentences = doc[\"content\"].split('.')\n",
    "                # Simple heuristic: take first two sentences from each document\n",
    "                key_sentences.extend(sentences[:2])\n",
    "            \n",
    "            combined_extract = \". \".join([s.strip() for s in key_sentences if s.strip()])\n",
    "            if len(combined_extract) > 100:  # Only summarize if long enough\n",
    "                summary = self.summarizer(combined_extract, max_length=80, min_length=30, do_sample=False)\n",
    "                return summary[0]['summary_text']\n",
    "            else:\n",
    "                return combined_extract\n",
    "    \n",
    "    def analyze_coverage(self, documents, summary):\n",
    "        \"\"\"Analyze how well the summary covers different sources\"\"\"\n",
    "        coverage = {}\n",
    "        summary_words = set(summary.lower().split())\n",
    "        \n",
    "        for doc in documents:\n",
    "            doc_words = set(doc[\"content\"].lower().split())\n",
    "            overlap = len(summary_words.intersection(doc_words))\n",
    "            coverage[doc[\"source\"]] = overlap / len(doc_words) if doc_words else 0\n",
    "        \n",
    "        return coverage\n",
    "\n",
    "# Initialize multi-document summarizer\n",
    "multi_summarizer = MultiDocumentSummarizer()\n",
    "\n",
    "print(\"üì∞ Source Articles:\")\n",
    "for i, article in enumerate(related_articles, 1):\n",
    "    print(f\"   {i}. {article['source']}: {len(article['content'].split())} words\")\n",
    "\n",
    "print(f\"\\nTotal content: {sum(len(doc['content'].split()) for doc in related_articles)} words\\n\")\n",
    "\n",
    "# Test different summarization strategies\n",
    "strategies = [\"concatenate\", \"individual_then_combine\", \"extractive\"]\n",
    "\n",
    "for strategy in strategies:\n",
    "    print(f\"üîÑ Strategy: {strategy.replace('_', ' ').title()}\")\n",
    "    \n",
    "    summary = multi_summarizer.summarize_collection(related_articles, strategy)\n",
    "    coverage = multi_summarizer.analyze_coverage(related_articles, summary)\n",
    "    \n",
    "    print(f\"   Summary ({len(summary.split())} words): {summary}\")\n",
    "    print(f\"   Source coverage: {', '.join([f'{source}: {score:.2f}' for source, score in coverage.items()])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Domain-Specific Summarization\n",
    "\n",
    "Handle different types of documents with specialized approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain-specific summarization\n",
    "print(\"üéØ Domain-Specific Summarization\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "class DomainSpecificSummarizer:\n",
    "    def __init__(self):\n",
    "        self.summarizer = pipeline(\"summarization\")\n",
    "    \n",
    "    def summarize_research_paper(self, abstract, content, max_length=100):\n",
    "        \"\"\"Summarize academic research papers\"\"\"\n",
    "        # Focus on methodology and findings\n",
    "        full_text = f\"Abstract: {abstract} Content: {content}\"\n",
    "        summary = self.summarizer(full_text, max_length=max_length, min_length=40, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    \n",
    "    def summarize_news_article(self, headline, content, max_length=80):\n",
    "        \"\"\"Summarize news articles focusing on key facts\"\"\"\n",
    "        # Include headline context\n",
    "        full_text = f\"Headline: {headline}. Article: {content}\"\n",
    "        summary = self.summarizer(full_text, max_length=max_length, min_length=30, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    \n",
    "    def summarize_meeting_notes(self, content, focus=\"action_items\"):\n",
    "        \"\"\"Summarize meeting notes with specific focus\"\"\"\n",
    "        if focus == \"action_items\":\n",
    "            prompt_text = f\"Focus on action items and decisions: {content}\"\n",
    "        elif focus == \"discussion\":\n",
    "            prompt_text = f\"Focus on main discussion points: {content}\"\n",
    "        else:\n",
    "            prompt_text = content\n",
    "        \n",
    "        summary = self.summarizer(prompt_text, max_length=100, min_length=30, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    \n",
    "    def summarize_product_reviews(self, reviews, aspect=\"overall\"):\n",
    "        \"\"\"Summarize product reviews focusing on specific aspects\"\"\"\n",
    "        combined_reviews = \" \".join(reviews)\n",
    "        \n",
    "        if aspect == \"pros\":\n",
    "            prompt_text = f\"Focus on positive aspects: {combined_reviews}\"\n",
    "        elif aspect == \"cons\":\n",
    "            prompt_text = f\"Focus on negative aspects: {combined_reviews}\"\n",
    "        else:\n",
    "            prompt_text = combined_reviews\n",
    "        \n",
    "        summary = self.summarizer(prompt_text, max_length=80, min_length=25, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "\n",
    "# Initialize domain-specific summarizer\n",
    "domain_summarizer = DomainSpecificSummarizer()\n",
    "\n",
    "# Test cases for different domains\n",
    "test_cases = [\n",
    "    {\n",
    "        \"type\": \"research_paper\",\n",
    "        \"data\": {\n",
    "            \"abstract\": \"This study investigates the effectiveness of transformer models in natural language processing tasks.\",\n",
    "            \"content\": \"\"\"\n",
    "            We conducted experiments on five benchmark datasets including GLUE and SuperGLUE. \n",
    "            Our proposed model achieved state-of-the-art results on text classification and \n",
    "            question answering tasks. The key innovation is a novel attention mechanism that \n",
    "            reduces computational complexity by 40% while maintaining performance. We trained \n",
    "            models with different sizes and evaluated their performance across multiple metrics. \n",
    "            Results show significant improvements in both accuracy and efficiency compared to \n",
    "            existing approaches.\n",
    "            \"\"\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"news_article\",\n",
    "        \"data\": {\n",
    "            \"headline\": \"Major Breakthrough in Renewable Energy Storage\",\n",
    "            \"content\": \"\"\"\n",
    "            Scientists at MIT have developed a revolutionary battery technology that could store \n",
    "            renewable energy for weeks rather than hours. The new lithium-metal batteries use \n",
    "            a novel electrolyte design that prevents dendrite formation, a major cause of \n",
    "            battery degradation. Initial tests show the batteries can retain 90% of their \n",
    "            capacity after 1000 charge cycles. This breakthrough could make renewable energy \n",
    "            much more reliable and cost-effective for grid storage applications.\n",
    "            \"\"\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"meeting_notes\",\n",
    "        \"data\": {\n",
    "            \"content\": \"\"\"\n",
    "            Team discussed the Q4 product roadmap. Sarah presented the user research findings \n",
    "            showing high demand for mobile features. John raised concerns about technical \n",
    "            feasibility and timeline. Decision made to prioritize mobile app development. \n",
    "            Action items: Sarah to create detailed requirements by Friday, John to assess \n",
    "            technical resources needed, Mike to prepare budget estimates. Next meeting \n",
    "            scheduled for next Tuesday to review progress.\n",
    "            \"\"\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"product_reviews\",\n",
    "        \"data\": {\n",
    "            \"reviews\": [\n",
    "                \"Great product with excellent battery life and fast performance. Camera quality is outstanding.\",\n",
    "                \"Love the design and build quality. However, the price is quite high for the features offered.\",\n",
    "                \"Amazing display quality and smooth user interface. Charging speed could be better though.\",\n",
    "                \"Good value for money. Some software bugs need to be fixed but overall satisfied.\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process each test case\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìã Test Case {i}: {case['type'].replace('_', ' ').title()}\")\n",
    "    \n",
    "    if case['type'] == 'research_paper':\n",
    "        summary = domain_summarizer.summarize_research_paper(\n",
    "            case['data']['abstract'], \n",
    "            case['data']['content']\n",
    "        )\n",
    "        print(f\"   üìÑ Research Summary: {summary}\")\n",
    "    \n",
    "    elif case['type'] == 'news_article':\n",
    "        summary = domain_summarizer.summarize_news_article(\n",
    "            case['data']['headline'], \n",
    "            case['data']['content']\n",
    "        )\n",
    "        print(f\"   üì∞ News Summary: {summary}\")\n",
    "    \n",
    "    elif case['type'] == 'meeting_notes':\n",
    "        action_summary = domain_summarizer.summarize_meeting_notes(\n",
    "            case['data']['content'], \n",
    "            focus=\"action_items\"\n",
    "        )\n",
    "        print(f\"   üìù Action Items: {action_summary}\")\n",
    "    \n",
    "    elif case['type'] == 'product_reviews':\n",
    "        overall_summary = domain_summarizer.summarize_product_reviews(\n",
    "            case['data']['reviews'], \n",
    "            aspect=\"overall\"\n",
    "        )\n",
    "        print(f\"   ‚≠ê Review Summary: {overall_summary}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Quality Evaluation\n",
    "\n",
    "Measure and improve summarization performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary quality evaluation and comparison\n",
    "print(\"üìä Summary Quality Evaluation\")\n",
    "print(\"=\" * 31)\n",
    "\n",
    "class SummaryEvaluator:\n",
    "    def __init__(self):\n",
    "        # Initialize different models for comparison\n",
    "        self.models = {\n",
    "            \"Default\": pipeline(\"summarization\"),\n",
    "            \"BART\": pipeline(\"summarization\", model=\"facebook/bart-large-cnn\"),\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            from rouge_score import rouge_scorer\n",
    "            self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "            self.rouge_available = True\n",
    "        except ImportError:\n",
    "            print(\"Note: ROUGE scorer not available. Install with 'pip install rouge-score'\")\n",
    "            self.rouge_available = False\n",
    "    \n",
    "    def generate_summaries(self, text, max_length=100):\n",
    "        \"\"\"Generate summaries using different models\"\"\"\n",
    "        summaries = {}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            try:\n",
    "                summary = model(text, max_length=max_length, min_length=30, do_sample=False)\n",
    "                summaries[model_name] = summary[0]['summary_text']\n",
    "            except Exception as e:\n",
    "                summaries[model_name] = f\"Error: {str(e)[:50]}...\"\n",
    "        \n",
    "        return summaries\n",
    "    \n",
    "    def calculate_basic_metrics(self, original_text, summary):\n",
    "        \"\"\"Calculate basic summary metrics\"\"\"\n",
    "        original_words = len(original_text.split())\n",
    "        summary_words = len(summary.split())\n",
    "        \n",
    "        return {\n",
    "            'compression_ratio': summary_words / original_words,\n",
    "            'original_length': original_words,\n",
    "            'summary_length': summary_words,\n",
    "            'reduction_percent': (1 - summary_words / original_words) * 100\n",
    "        }\n",
    "    \n",
    "    def calculate_rouge_scores(self, reference, summary):\n",
    "        \"\"\"Calculate ROUGE scores if available\"\"\"\n",
    "        if not self.rouge_available:\n",
    "            return {\"rouge1\": \"N/A\", \"rouge2\": \"N/A\", \"rougeL\": \"N/A\"}\n",
    "        \n",
    "        scores = self.rouge_scorer.score(reference, summary)\n",
    "        return {\n",
    "            'rouge1': scores['rouge1'].fmeasure,\n",
    "            'rouge2': scores['rouge2'].fmeasure,\n",
    "            'rougeL': scores['rougeL'].fmeasure\n",
    "        }\n",
    "    \n",
    "    def evaluate_coherence(self, summary):\n",
    "        \"\"\"Simple coherence evaluation based on sentence structure\"\"\"\n",
    "        sentences = summary.split('.')\n",
    "        sentence_count = len([s for s in sentences if s.strip()])\n",
    "        \n",
    "        # Simple heuristics for coherence\n",
    "        avg_sentence_length = len(summary.split()) / max(sentence_count, 1)\n",
    "        has_connecting_words = any(word in summary.lower() for word in \n",
    "                                 ['however', 'therefore', 'moreover', 'furthermore', 'additionally'])\n",
    "        \n",
    "        coherence_score = min(1.0, avg_sentence_length / 15)  # Normalize to 0-1\n",
    "        if has_connecting_words:\n",
    "            coherence_score += 0.1\n",
    "        \n",
    "        return min(1.0, coherence_score)\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = SummaryEvaluator()\n",
    "\n",
    "# Test article for evaluation\n",
    "evaluation_text = \"\"\"\n",
    "The global semiconductor industry is facing unprecedented challenges due to supply chain \n",
    "disruptions and increasing demand for electronic devices. Major chip manufacturers like \n",
    "TSMC and Intel are investing billions of dollars in new fabrication facilities to meet \n",
    "growing demand. However, the complexity of modern chip manufacturing means that new \n",
    "facilities take several years to become operational. The shortage has affected numerous \n",
    "industries, from automotive to consumer electronics, with car manufacturers being \n",
    "particularly hard hit. Some automakers have had to temporarily halt production lines \n",
    "due to lack of chips. Government initiatives in the United States, Europe, and Asia \n",
    "are aimed at building domestic chip manufacturing capabilities to reduce dependence \n",
    "on foreign suppliers. Industry experts predict that the shortage will gradually ease \n",
    "over the next two years as new capacity comes online, but the experience has highlighted \n",
    "the strategic importance of semiconductors in the modern economy.\n",
    "\"\"\"\n",
    "\n",
    "# Reference summary for comparison (human-written)\n",
    "reference_summary = \"\"\"\n",
    "The semiconductor industry faces supply chain disruptions and high demand, leading to \n",
    "shortages affecting automotive and electronics sectors. Major manufacturers are investing \n",
    "in new facilities, while governments promote domestic production capabilities. The shortage \n",
    "should ease within two years as new capacity becomes available.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìÑ Original Text: {len(evaluation_text.split())} words\")\n",
    "print(f\"üìù Reference Summary: {len(reference_summary.split())} words\\n\")\n",
    "\n",
    "# Generate summaries with different models\n",
    "generated_summaries = evaluator.generate_summaries(evaluation_text)\n",
    "\n",
    "# Evaluate each summary\n",
    "print(\"üîç Model Comparison:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "for model_name, summary in generated_summaries.items():\n",
    "    if not summary.startswith(\"Error:\"):\n",
    "        print(f\"\\nü§ñ {model_name} Model:\")\n",
    "        print(f\"   Summary: {summary}\")\n",
    "        \n",
    "        # Basic metrics\n",
    "        basic_metrics = evaluator.calculate_basic_metrics(evaluation_text, summary)\n",
    "        print(f\"   Length: {basic_metrics['summary_length']} words ({basic_metrics['reduction_percent']:.1f}% reduction)\")\n",
    "        print(f\"   Compression: {basic_metrics['compression_ratio']:.3f}\")\n",
    "        \n",
    "        # ROUGE scores (if available)\n",
    "        rouge_scores = evaluator.calculate_rouge_scores(reference_summary, summary)\n",
    "        if isinstance(rouge_scores['rouge1'], float):\n",
    "            print(f\"   ROUGE-1: {rouge_scores['rouge1']:.3f}\")\n",
    "            print(f\"   ROUGE-2: {rouge_scores['rouge2']:.3f}\")\n",
    "            print(f\"   ROUGE-L: {rouge_scores['rougeL']:.3f}\")\n",
    "        \n",
    "        # Coherence score\n",
    "        coherence = evaluator.evaluate_coherence(summary)\n",
    "        print(f\"   Coherence: {coherence:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {model_name} Model: {summary}\")\n",
    "\n",
    "# Summary quality tips\n",
    "print(\"\\nüí° Summary Quality Tips:\")\n",
    "print(\"=\" * 24)\n",
    "quality_tips = [\n",
    "    \"Maintain key information while reducing length\",\n",
    "    \"Ensure logical flow and coherence\",\n",
    "    \"Preserve important entities and facts\",\n",
    "    \"Use appropriate compression ratios for the task\",\n",
    "    \"Consider domain-specific requirements\",\n",
    "    \"Evaluate summaries with multiple metrics\"\n",
    "]\n",
    "\n",
    "for i, tip in enumerate(quality_tips, 1):\n",
    "    print(f\"   {i}. {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "**What you've learned about text summarization:**\n",
    "\n",
    "‚úÖ **Basic Summarization**: Use pre-trained models for quick text condensation  \n",
    "‚úÖ **Parameter Control**: Fine-tune summary length, style, and sampling strategies  \n",
    "‚úÖ **Multi-Document Processing**: Combine and summarize multiple related sources  \n",
    "‚úÖ **Domain Adaptation**: Handle different document types with specialized approaches  \n",
    "‚úÖ **Quality Evaluation**: Measure and compare summary performance with multiple metrics  \n",
    "‚úÖ **Compression Strategies**: Balance information retention with length reduction  \n",
    "‚úÖ **Real-world Applications**: Build production-ready summarization systems  \n",
    "\n",
    "## üîß Best Practices\n",
    "\n",
    "1. **Choose appropriate models** for your specific domain and use case\n",
    "2. **Set reasonable length parameters** based on source content and requirements\n",
    "3. **Evaluate summaries systematically** using both automatic metrics and human judgment\n",
    "4. **Consider the target audience** when determining summary style and detail level\n",
    "5. **Handle edge cases** like very short or very long input documents\n",
    "6. **Preserve critical information** like names, dates, and key facts\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Ready for the next challenge?\n",
    "\n",
    "**Continue to**: `10_fine_tuning_basics.ipynb` - Learn about customizing models for your specific needs!\n",
    "\n",
    "**Practice**: Try summarizing documents from your domain (legal contracts, research papers, news articles)!\n",
    "\n",
    "Great work mastering text summarization! üìö"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}