{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Hugging Face 🎯\n",
    "\n",
    "Text classification is one of the most common NLP tasks - assigning categories or labels to text documents. From spam detection to sentiment analysis, topic classification to intent recognition, this fundamental skill powers countless applications.\n",
    "\n",
    "## What is Text Classification?\n",
    "\n",
    "**Text Classification** assigns predefined categories to text:\n",
    "- **Input**: Text document\n",
    "- **Output**: Category label(s) with confidence scores\n",
    "- **Examples**: Email spam detection, news categorization, customer feedback analysis\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll know how to:\n",
    "1. Use pre-trained classification models effectively\n",
    "2. Fine-tune models on custom datasets\n",
    "3. Implement multi-class and multi-label classification\n",
    "4. Evaluate model performance with proper metrics\n",
    "5. Handle imbalanced datasets and edge cases\n",
    "6. Deploy classification models in production\n",
    "\n",
    "Let's build some powerful classifiers! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-trained Classification Models\n",
    "\n",
    "Let's explore various pre-trained models for different classification tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different pre-trained classification models\n",
    "print(\"🎯 Pre-trained Classification Models\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Test texts\n",
    "test_texts = [\n",
    "    \"I absolutely love this new product! It's amazing!\",\n",
    "    \"This movie was terrible and boring. Waste of time.\",\n",
    "    \"The weather is okay today, nothing special.\",\n",
    "    \"I'm so excited about this opportunity!\",\n",
    "    \"This is frustrating and makes me angry.\"\n",
    "]\n",
    "\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    result = sentiment_classifier(text)[0]\n",
    "    emoji = \"😊\" if result['label'] == 'POSITIVE' else \"😞\"\n",
    "    print(f\"{i}. {emoji} '{text}'\")\n",
    "    print(f\"   → {result['label']} (confidence: {result['score']:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zero-Shot Classification\n",
    "\n",
    "Classify text into custom categories without training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot classification\n",
    "print(\"🎯 Zero-Shot Text Classification\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Customer service tickets\n",
    "customer_tickets = [\n",
    "    \"My order hasn't arrived yet and it's been 2 weeks.\",\n",
    "    \"The product broke after just one day of use.\",\n",
    "    \"I want to return this item for a full refund.\",\n",
    "    \"Can you help me track my package?\",\n",
    "    \"The app keeps crashing when I try to log in.\",\n",
    "    \"Your customer service representative was very helpful!\"\n",
    "]\n",
    "\n",
    "# Define categories\n",
    "categories = [\"shipping\", \"product quality\", \"returns\", \"technical support\", \"compliment\"]\n",
    "\n",
    "print(f\"Categories: {categories}\\n\")\n",
    "\n",
    "for i, ticket in enumerate(customer_tickets, 1):\n",
    "    result = zero_shot_classifier(ticket, categories)\n",
    "    \n",
    "    print(f\"{i}. '{ticket}'\")\n",
    "    print(f\"   Category: {result['labels'][0]} ({result['scores'][0]:.3f})\")\n",
    "    print(f\"   Top 3: {list(zip(result['labels'][:3], [f'{s:.3f}' for s in result['scores'][:3]]))}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Dataset and Fine-tuning\n",
    "\n",
    "Let's create a custom movie review dataset and fine-tune a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample movie review dataset\n",
    "print(\"Creating Movie Review Dataset\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "movie_reviews = {\n",
    "    'text': [\n",
    "        \"This movie was absolutely fantastic! Great acting and storyline.\",\n",
    "        \"Terrible film with poor acting and a confusing plot.\",\n",
    "        \"One of the best movies I've ever seen. Highly recommended!\",\n",
    "        \"Boring and predictable. Not worth your time.\",\n",
    "        \"Amazing cinematography and brilliant performances throughout.\",\n",
    "        \"The worst movie I've watched this year. Complete waste of money.\",\n",
    "        \"Good movie with some great moments, though a bit slow at times.\",\n",
    "        \"Outstanding film that deserves all the awards it received.\",\n",
    "        \"Disappointing sequel that doesn't live up to the original.\",\n",
    "        \"Incredible story with perfect casting and direction.\",\n",
    "        \"Average movie, nothing special but not terrible either.\",\n",
    "        \"Absolutely loved it! Will definitely watch it again.\",\n",
    "        \"Poor dialogue and weak character development throughout.\",\n",
    "        \"Masterpiece of cinema with stunning visuals and sound.\",\n",
    "        \"Not impressed. Expected much better from this director.\",\n",
    "        \"Excellent acting and a compelling storyline from start to finish.\",\n",
    "        \"Terrible editing and pacing made this unwatchable.\",\n",
    "        \"Beautiful film that touched my heart. Truly moving experience.\",\n",
    "        \"Complete disaster. Couldn't even finish watching it.\",\n",
    "        \"Great entertainment value with perfect balance of action and humor.\"\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # 1=positive, 0=negative\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(movie_reviews)\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n",
    "\n",
    "# Show sample reviews\n",
    "print(\"\\nSample reviews:\")\n",
    "for i in range(3):\n",
    "    label_text = \"Positive\" if df.iloc[i]['label'] == 1 else \"Negative\"\n",
    "    print(f\"{i+1}. [{label_text}] '{df.iloc[i]['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Let's evaluate classification performance with proper metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "print(\"Model Evaluation\")\n",
    "print(\"=\" * 18)\n",
    "\n",
    "# Use pre-trained model for evaluation demo\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Get predictions for our dataset\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for text, true_label in zip(df['text'], df['label']):\n",
    "    pred = classifier(text)[0]\n",
    "    # Convert model output to binary\n",
    "    pred_label = 1 if pred['label'] == 'POSITIVE' else 0\n",
    "    predictions.append(pred_label)\n",
    "    true_labels.append(true_label)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, \n",
    "                          target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-label Classification\n",
    "\n",
    "Handle cases where text can belong to multiple categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label classification example\n",
    "print(\"Multi-label Classification\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "# News articles that can belong to multiple categories\n",
    "news_articles = [\n",
    "    \"Apple announces new iPhone with advanced AI features for business users.\",\n",
    "    \"Climate change affects global economy and technology investments.\",\n",
    "    \"New medical AI breakthrough helps doctors diagnose diseases faster.\",\n",
    "    \"Sports teams use technology and data analytics to improve performance.\",\n",
    "    \"Government announces new policies for technology and healthcare sectors.\"\n",
    "]\n",
    "\n",
    "categories = [\"Technology\", \"Business\", \"Health\", \"Politics\", \"Sports\", \"Environment\"]\n",
    "\n",
    "multi_label_classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "print(f\"Categories: {categories}\\n\")\n",
    "\n",
    "for i, article in enumerate(news_articles, 1):\n",
    "    result = multi_label_classifier(article, categories, multi_label=True)\n",
    "    \n",
    "    print(f\"{i}. '{article}'\")\n",
    "    print(\"    Relevant categories (score > 0.5):\")\n",
    "    \n",
    "    relevant = [(label, score) for label, score in zip(result['labels'], result['scores']) if score > 0.5]\n",
    "    \n",
    "    if relevant:\n",
    "        for label, score in relevant:\n",
    "            print(f\"       {label}: {score:.3f}\")\n",
    "    else:\n",
    "        print(f\"       Best match: {result['labels'][0]} ({result['scores'][0]:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Optimization\n",
    "\n",
    "Compare different models and optimize for speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"Performance Optimization\")\n",
    "print(\"=\" * 26)\n",
    "\n",
    "import time\n",
    "\n",
    "# Models to compare\n",
    "models = [\n",
    "    (\"DistilBERT\", \"distilbert-base-uncased-finetuned-sst-2-english\"),\n",
    "    (\"RoBERTa\", \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "]\n",
    "\n",
    "test_text = \"This movie was absolutely fantastic with great acting!\"\n",
    "batch_texts = [test_text] * 50  # Batch for speed testing\n",
    "\n",
    "print(f\"Test text: '{test_text}'\")\n",
    "print(f\"Batch size: {len(batch_texts)} texts\\n\")\n",
    "\n",
    "for model_name, model_path in models:\n",
    "    try:\n",
    "        print(f\"Testing {model_name}:\")\n",
    "        \n",
    "        # Load model\n",
    "        start_time = time.time()\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_path)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        # Single inference\n",
    "        start_time = time.time()\n",
    "        result = classifier(test_text)[0]\n",
    "        single_time = time.time() - start_time\n",
    "        \n",
    "        # Batch inference\n",
    "        start_time = time.time()\n",
    "        batch_results = classifier(batch_texts)\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   Load time: {load_time:.3f}s\")\n",
    "        print(f\"   Single inference: {single_time*1000:.1f}ms\")\n",
    "        print(f\"   Batch inference: {batch_time:.3f}s ({batch_time/len(batch_texts)*1000:.1f}ms per text)\")\n",
    "        print(f\"   Result: {result['label']} ({result['score']:.3f})\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {str(e)[:50]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-world Application\n",
    "\n",
    "Let's build a comprehensive customer feedback classification system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Feedback Classification System\n",
    "print(\"Customer Feedback Classifier\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "class FeedbackClassifier:\n",
    "    def __init__(self):\n",
    "        self.sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "        self.zero_shot_classifier = pipeline(\"zero-shot-classification\")\n",
    "        \n",
    "        self.categories = [\"product quality\", \"shipping\", \"customer service\", \n",
    "                          \"pricing\", \"website issues\", \"returns\"]\n",
    "        self.urgency_levels = [\"urgent\", \"medium\", \"low\"]\n",
    "    \n",
    "    def classify(self, text):\n",
    "        # Sentiment\n",
    "        sentiment = self.sentiment_classifier(text)[0]\n",
    "        \n",
    "        # Category\n",
    "        category = self.zero_shot_classifier(text, self.categories)['labels'][0]\n",
    "        \n",
    "        # Urgency\n",
    "        urgency = self.zero_shot_classifier(text, self.urgency_levels)['labels'][0]\n",
    "        \n",
    "        return {\n",
    "            'sentiment': sentiment['label'],\n",
    "            'sentiment_score': sentiment['score'],\n",
    "            'category': category,\n",
    "            'urgency': urgency,\n",
    "            'text': text\n",
    "        }\n",
    "    \n",
    "    def generate_response_plan(self, classification):\n",
    "        \"\"\"Generate action plan based on classification\"\"\"\n",
    "        actions = []\n",
    "        \n",
    "        if classification['sentiment'] == 'NEGATIVE':\n",
    "            if classification['sentiment_score'] > 0.8:\n",
    "                actions.append(\" Priority: Immediate attention required\")\n",
    "            actions.append(\" Apologize and provide solution\")\n",
    "        else:\n",
    "            actions.append(\" Thank customer for positive feedback\")\n",
    "        \n",
    "        if classification['urgency'] == 'urgent':\n",
    "            actions.append(\" Respond within 2 hours\")\n",
    "        elif classification['urgency'] == 'medium':\n",
    "            actions.append(\" Respond within 24 hours\")\n",
    "        else:\n",
    "            actions.append(\" Respond within 3 days\")\n",
    "        \n",
    "        category_actions = {\n",
    "            'product quality': ' Forward to product team',\n",
    "            'shipping': ' Contact logistics team',\n",
    "            'customer service': ' Escalate to supervisor',\n",
    "            'pricing': ' Review pricing concerns',\n",
    "            'website issues': ' Forward to tech team',\n",
    "            'returns': '↩ Process return request'\n",
    "        }\n",
    "        \n",
    "        if classification['category'] in category_actions:\n",
    "            actions.append(category_actions[classification['category']])\n",
    "        \n",
    "        return actions\n",
    "\n",
    "# Initialize classifier\n",
    "feedback_classifier = FeedbackClassifier()\n",
    "print(\"Feedback classifier initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the feedback classifier\n",
    "test_feedbacks = [\n",
    "    \"The product broke after one day! I'm extremely frustrated and want a refund!\",\n",
    "    \"Great product, fast shipping. Very satisfied with my purchase.\",\n",
    "    \"The website keeps crashing during checkout. Please fix this issue.\",\n",
    "    \"Customer service was unhelpful and rude. Very disappointed.\",\n",
    "    \"Good quality but took too long to arrive. Expected faster delivery.\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Feedback Analysis Results\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "for i, feedback in enumerate(test_feedbacks, 1):\n",
    "    result = feedback_classifier.classify(feedback)\n",
    "    actions = feedback_classifier.generate_response_plan(result)\n",
    "    \n",
    "    print(f\"\\n Feedback {i}:\")\n",
    "    print(f\"'{feedback}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(f\" Classification:\")\n",
    "    print(f\"   Sentiment: {result['sentiment']} ({result['sentiment_score']:.3f})\")\n",
    "    print(f\"   Category: {result['category']}\")\n",
    "    print(f\"   Urgency: {result['urgency']}\")\n",
    "    \n",
    "    print(f\"\\n Action Plan:\")\n",
    "    for action in actions:\n",
    "        print(f\"   {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Key Takeaways\n",
    "\n",
    "**What you've learned about text classification:**\n",
    "\n",
    "✅ **Pre-trained Models**: Leverage existing models for quick solutions  \n",
    "✅ **Zero-Shot Classification**: Classify without training data  \n",
    "✅ **Fine-tuning**: Customize models for specific domains  \n",
    "✅ **Multi-label Classification**: Handle multiple categories per text  \n",
    "✅ **Model Evaluation**: Use proper metrics and validation  \n",
    "✅ **Performance Optimization**: Speed and efficiency considerations  \n",
    "✅ **Real-world Applications**: Complete classification systems  \n",
    "\n",
    "## 🔧 Best Practices\n",
    "\n",
    "1. **Start with pre-trained models** before building custom ones\n",
    "2. **Use zero-shot classification** for rapid prototyping\n",
    "3. **Evaluate thoroughly** with proper train/validation splits\n",
    "4. **Consider batch processing** for production efficiency\n",
    "5. **Handle edge cases** and class imbalance appropriately\n",
    "6. **Monitor performance** in production environments\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "Ready for the next challenge?\n",
    "\n",
    "**Continue to**: `06_token_classification.ipynb` - Learn about sequence labeling and named entity recognition!\n",
    "\n",
    "**Practice**: Try building classifiers for your own domain-specific data!\n",
    "\n",
    "Great work mastering text classification! 🎊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
